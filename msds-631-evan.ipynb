{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pytorch Implementation of a Keras Architecture \nby Amee Tan & Evan Chen \n\n\n### Task: \nGiven pictures of handwritten names, predict the name that was written in the picture. \n\n### Goal:\nCurrently, there are no published Pytorch notebooks for this task. Our goal was to take an existing Keras architecture and implement it in Pytorch. The original Keras notebook can be found here: https://www.kaggle.com/samfc10/handwriting-recognition-using-crnn-in-keras\n\n\n### Data: \nTraining set: 331,059 images <br>\nValidation set: 41,382 images <br>\nTesting set: 41,382 images <br>\nSource: https://www.kaggle.com/landlord/handwriting-recognition\n","metadata":{}},{"cell_type":"code","source":"!pip install torchinfo","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:05:07.458715Z","iopub.execute_input":"2021-08-10T17:05:07.459255Z","iopub.status.idle":"2021-08-10T17:05:16.149923Z","shell.execute_reply.started":"2021-08-10T17:05:07.459124Z","shell.execute_reply":"2021-08-10T17:05:16.148907Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchinfo\n  Downloading torchinfo-1.5.3-py3-none-any.whl (19 kB)\nInstalling collected packages: torchinfo\nSuccessfully installed torchinfo-1.5.3\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\n\nfrom torchinfo import summary\n\n# Mixed Precision Training\nfrom torch.cuda.amp import autocast\nfrom torch.cuda.amp import GradScaler\n","metadata":{"id":"hbeM9aEXGgh1","execution":{"iopub.status.busy":"2021-08-10T17:05:16.151865Z","iopub.execute_input":"2021-08-10T17:05:16.152291Z","iopub.status.idle":"2021-08-10T17:05:17.871997Z","shell.execute_reply.started":"2021-08-10T17:05:16.152247Z","shell.execute_reply":"2021-08-10T17:05:17.871081Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{"id":"09hv06ZVGGzy"}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_train_v2.csv')\ndf_valid = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_validation_v2.csv') # Locally\ndf_test = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_test_v2.csv')\n\ndf_train.head()","metadata":{"id":"y6xlYTIjBQFe","outputId":"a1c7a3bf-ad91-4722-e580-024208f9cef1","execution":{"iopub.status.busy":"2021-08-10T17:05:17.875044Z","iopub.execute_input":"2021-08-10T17:05:17.875429Z","iopub.status.idle":"2021-08-10T17:05:18.820383Z","shell.execute_reply.started":"2021-08-10T17:05:17.875380Z","shell.execute_reply":"2021-08-10T17:05:18.819483Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"          FILENAME   IDENTITY\n0  TRAIN_00001.jpg  BALTHAZAR\n1  TRAIN_00002.jpg      SIMON\n2  TRAIN_00003.jpg      BENES\n3  TRAIN_00004.jpg    LA LOVE\n4  TRAIN_00005.jpg     DAPHNE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FILENAME</th>\n      <th>IDENTITY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRAIN_00001.jpg</td>\n      <td>BALTHAZAR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRAIN_00002.jpg</td>\n      <td>SIMON</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRAIN_00003.jpg</td>\n      <td>BENES</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRAIN_00004.jpg</td>\n      <td>LA LOVE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRAIN_00005.jpg</td>\n      <td>DAPHNE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Are there any null values? \n\nprint(\"Number of nulls in train:\", df_train['IDENTITY'].isnull().sum())\nprint(\"Number of nulls in valid:\",df_valid['IDENTITY'].isnull().sum())","metadata":{"id":"BS9uEjhhJZRV","outputId":"0472dff6-650b-405e-9873-8deea2e3f17d","execution":{"iopub.status.busy":"2021-08-10T17:05:18.823803Z","iopub.execute_input":"2021-08-10T17:05:18.824110Z","iopub.status.idle":"2021-08-10T17:05:18.871913Z","shell.execute_reply.started":"2021-08-10T17:05:18.824080Z","shell.execute_reply":"2021-08-10T17:05:18.870806Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Number of nulls in train: 565\nNumber of nulls in valid: 78\n","output_type":"stream"}]},{"cell_type":"code","source":"# Drop the rows with null values for the label (IDENTITY column)\n\ndf_train.dropna(inplace=True)\ndf_valid.dropna(inplace=True)\ndf_test.dropna(inplace=True)","metadata":{"id":"9MWDoHyeKRJe","execution":{"iopub.status.busy":"2021-08-10T17:05:18.873532Z","iopub.execute_input":"2021-08-10T17:05:18.873919Z","iopub.status.idle":"2021-08-10T17:05:19.002058Z","shell.execute_reply.started":"2021-08-10T17:05:18.873879Z","shell.execute_reply":"2021-08-10T17:05:19.001071Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# How many unreadable images are there in each set? \nprint(len(df_train.loc[df_train['IDENTITY']=='UNREADABLE']))\nprint(len(df_valid.loc[df_valid['IDENTITY']=='UNREADABLE']))\nprint(len(df_test.loc[df_test['IDENTITY']=='UNREADABLE']))","metadata":{"id":"XPeLYqcZCo6v","outputId":"765bd88e-b850-4e8b-e734-d79ac6e31a36","execution":{"iopub.status.busy":"2021-08-10T17:05:19.003599Z","iopub.execute_input":"2021-08-10T17:05:19.003986Z","iopub.status.idle":"2021-08-10T17:05:19.074827Z","shell.execute_reply.started":"2021-08-10T17:05:19.003946Z","shell.execute_reply":"2021-08-10T17:05:19.073796Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"102\n12\n11\n","output_type":"stream"}]},{"cell_type":"code","source":"# Remove the unreadable images from the train and valid sets\n\ndf_train = df_train[df_train['IDENTITY'] != 'UNREADABLE']\ndf_valid = df_valid[df_valid['IDENTITY'] != 'UNREADABLE']\ndf_test = df_test[df_test['IDENTITY'] != 'UNREADABLE']\n\ndf_train.reset_index(inplace = True, drop=True) \ndf_valid.reset_index(inplace = True, drop=True)\ndf_test.reset_index(inplace = True, drop=True)\n\n","metadata":{"id":"v4VEmmGqDv0l","execution":{"iopub.status.busy":"2021-08-10T17:05:19.076318Z","iopub.execute_input":"2021-08-10T17:05:19.076723Z","iopub.status.idle":"2021-08-10T17:05:19.165634Z","shell.execute_reply.started":"2021-08-10T17:05:19.076685Z","shell.execute_reply":"2021-08-10T17:05:19.164661Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# There are some labels that are lowercase. Convert all labels to uppercase\n\ndf_train['IDENTITY'] = df_train['IDENTITY'].str.upper()\ndf_valid['IDENTITY'] = df_valid['IDENTITY'].str.upper()\ndf_test['IDENTITY'] = df_test['IDENTITY'].str.upper()","metadata":{"id":"oY96cw9hFxjb","execution":{"iopub.status.busy":"2021-08-10T17:05:19.168372Z","iopub.execute_input":"2021-08-10T17:05:19.168774Z","iopub.status.idle":"2021-08-10T17:05:19.404894Z","shell.execute_reply.started":"2021-08-10T17:05:19.168735Z","shell.execute_reply":"2021-08-10T17:05:19.403934Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# How long is the longest name that we'll encounter? \n\ndf_train['LABEL LENGTH'] = df_train['IDENTITY'].apply(lambda x: len(x))\ndf_valid['LABEL LENGTH'] = df_valid['IDENTITY'].apply(lambda x: len(x))\ndf_test['LABEL LENGTH'] = df_test['IDENTITY'].apply(lambda x: len(x))\n\nprint(df_train.describe()) # 34 for the training set \nprint(df_valid.describe()) # 21 for the valid set\nprint(df_test.describe()) # 24 for the test set","metadata":{"id":"yztN_FayJEyr","outputId":"95ecf2ad-d35d-4153-cbd1-9d396797af67","execution":{"iopub.status.busy":"2021-08-10T17:05:19.407122Z","iopub.execute_input":"2021-08-10T17:05:19.407469Z","iopub.status.idle":"2021-08-10T17:05:19.695908Z","shell.execute_reply.started":"2021-08-10T17:05:19.407437Z","shell.execute_reply":"2021-08-10T17:05:19.694769Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"        LABEL LENGTH\ncount  330294.000000\nmean        6.546531\nstd         2.123296\nmin         1.000000\n25%         5.000000\n50%         6.000000\n75%         7.000000\nmax        34.000000\n       LABEL LENGTH\ncount  41280.000000\nmean       6.556613\nstd        2.127069\nmin        1.000000\n25%        5.000000\n50%        6.000000\n75%        7.000000\nmax       21.000000\n       LABEL LENGTH\ncount  41289.000000\nmean       6.545860\nstd        2.137525\nmin        1.000000\n25%        5.000000\n50%        6.000000\n75%        7.000000\nmax       24.000000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prepare Images ","metadata":{"id":"6VY8MexFGVl5"}},{"cell_type":"code","source":"# Code borrowed from https://www.kaggle.com/samfc10/handwriting-recognition-using-crnn-in-keras\n\ndef preprocess(img):\n    (h, w) = img.shape\n    \n    final_img = np.ones([64, 256])*255 # blank white image\n    \n    # Width and height are cropped if greater than 256x64; If smaler, image is padded with white pixesls\n    if w > 256:\n        img = img[:, :256]\n        \n    if h > 64:\n        img = img[:64, :]\n    \n    \n    final_img[:h, :w] = img\n    # Rotate clockwise\n    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)","metadata":{"id":"wmOClSZDF-Ca","execution":{"iopub.status.busy":"2021-08-10T17:05:19.697607Z","iopub.execute_input":"2021-08-10T17:05:19.698029Z","iopub.status.idle":"2021-08-10T17:05:19.704477Z","shell.execute_reply.started":"2021-08-10T17:05:19.697987Z","shell.execute_reply":"2021-08-10T17:05:19.703502Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Labels: Convert names into a sequence of integers","metadata":{"id":"kUws6oFtPWBK"}},{"cell_type":"code","source":"# Code adapted from same notebook as above \n\nalphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\nmax_str_len = 64 # max length of input labels\nnum_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\nnum_of_timestamps = 64 # max length of predicted labels \n\ndef label_to_num(label):\n    label_num = []\n    for ch in label:\n        label_num.append(alphabets.find(ch))\n        \n    return np.array(label_num)\n\ndef num_to_label(num):\n    ret = \"\"\n    for ch in num:\n        if ch == -1:  # CTC Blank\n            break\n        else:\n            ret+=alphabets[ch]\n    return ret","metadata":{"id":"zgK3fYYFOZQ7","execution":{"iopub.status.busy":"2021-08-10T17:05:19.705997Z","iopub.execute_input":"2021-08-10T17:05:19.706643Z","iopub.status.idle":"2021-08-10T17:05:19.715382Z","shell.execute_reply.started":"2021-08-10T17:05:19.706601Z","shell.execute_reply":"2021-08-10T17:05:19.714299Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def encode_label(row):\n    label = np.zeros(max_str_len)\n    for i in range(max_str_len):\n        label[0:len(row)] = label_to_num(row)\n\n    return label\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:05:19.716838Z","iopub.execute_input":"2021-08-10T17:05:19.717246Z","iopub.status.idle":"2021-08-10T17:05:19.725556Z","shell.execute_reply.started":"2021-08-10T17:05:19.717205Z","shell.execute_reply":"2021-08-10T17:05:19.724483Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df_train['ENCODED LABEL'] = df_train['IDENTITY'].apply(lambda x: encode_label(x))\ndf_valid['ENCODED LABEL'] = df_valid['IDENTITY'].apply(lambda x: encode_label(x))\n\ndf_train","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:05:19.727051Z","iopub.execute_input":"2021-08-10T17:05:19.727495Z","iopub.status.idle":"2021-08-10T17:07:56.562567Z","shell.execute_reply.started":"2021-08-10T17:05:19.727453Z","shell.execute_reply":"2021-08-10T17:07:56.561663Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                FILENAME       IDENTITY  LABEL LENGTH  \\\n0        TRAIN_00001.jpg      BALTHAZAR             9   \n1        TRAIN_00002.jpg          SIMON             5   \n2        TRAIN_00003.jpg          BENES             5   \n3        TRAIN_00004.jpg        LA LOVE             7   \n4        TRAIN_00005.jpg         DAPHNE             6   \n...                  ...            ...           ...   \n330289  TRAIN_330957.jpg          LENNY             5   \n330290  TRAIN_330958.jpg        TIFFANY             7   \n330291  TRAIN_330959.jpg  COUTINHO DESA            13   \n330292  TRAIN_330960.jpg         MOURAD             6   \n330293  TRAIN_330961.jpg        HELOISE             7   \n\n                                            ENCODED LABEL  \n0       [1.0, 0.0, 11.0, 19.0, 7.0, 0.0, 25.0, 0.0, 17...  \n1       [18.0, 8.0, 12.0, 14.0, 13.0, 0.0, 0.0, 0.0, 0...  \n2       [1.0, 4.0, 13.0, 4.0, 18.0, 0.0, 0.0, 0.0, 0.0...  \n3       [11.0, 0.0, 28.0, 11.0, 14.0, 21.0, 4.0, 0.0, ...  \n4       [3.0, 0.0, 15.0, 7.0, 13.0, 4.0, 0.0, 0.0, 0.0...  \n...                                                   ...  \n330289  [11.0, 4.0, 13.0, 13.0, 24.0, 0.0, 0.0, 0.0, 0...  \n330290  [19.0, 8.0, 5.0, 5.0, 0.0, 13.0, 24.0, 0.0, 0....  \n330291  [2.0, 14.0, 20.0, 19.0, 8.0, 13.0, 7.0, 14.0, ...  \n330292  [12.0, 14.0, 20.0, 17.0, 0.0, 3.0, 0.0, 0.0, 0...  \n330293  [7.0, 4.0, 11.0, 14.0, 8.0, 18.0, 4.0, 0.0, 0....  \n\n[330294 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FILENAME</th>\n      <th>IDENTITY</th>\n      <th>LABEL LENGTH</th>\n      <th>ENCODED LABEL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRAIN_00001.jpg</td>\n      <td>BALTHAZAR</td>\n      <td>9</td>\n      <td>[1.0, 0.0, 11.0, 19.0, 7.0, 0.0, 25.0, 0.0, 17...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRAIN_00002.jpg</td>\n      <td>SIMON</td>\n      <td>5</td>\n      <td>[18.0, 8.0, 12.0, 14.0, 13.0, 0.0, 0.0, 0.0, 0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRAIN_00003.jpg</td>\n      <td>BENES</td>\n      <td>5</td>\n      <td>[1.0, 4.0, 13.0, 4.0, 18.0, 0.0, 0.0, 0.0, 0.0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRAIN_00004.jpg</td>\n      <td>LA LOVE</td>\n      <td>7</td>\n      <td>[11.0, 0.0, 28.0, 11.0, 14.0, 21.0, 4.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRAIN_00005.jpg</td>\n      <td>DAPHNE</td>\n      <td>6</td>\n      <td>[3.0, 0.0, 15.0, 7.0, 13.0, 4.0, 0.0, 0.0, 0.0...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330289</th>\n      <td>TRAIN_330957.jpg</td>\n      <td>LENNY</td>\n      <td>5</td>\n      <td>[11.0, 4.0, 13.0, 13.0, 24.0, 0.0, 0.0, 0.0, 0...</td>\n    </tr>\n    <tr>\n      <th>330290</th>\n      <td>TRAIN_330958.jpg</td>\n      <td>TIFFANY</td>\n      <td>7</td>\n      <td>[19.0, 8.0, 5.0, 5.0, 0.0, 13.0, 24.0, 0.0, 0....</td>\n    </tr>\n    <tr>\n      <th>330291</th>\n      <td>TRAIN_330959.jpg</td>\n      <td>COUTINHO DESA</td>\n      <td>13</td>\n      <td>[2.0, 14.0, 20.0, 19.0, 8.0, 13.0, 7.0, 14.0, ...</td>\n    </tr>\n    <tr>\n      <th>330292</th>\n      <td>TRAIN_330960.jpg</td>\n      <td>MOURAD</td>\n      <td>6</td>\n      <td>[12.0, 14.0, 20.0, 17.0, 0.0, 3.0, 0.0, 0.0, 0...</td>\n    </tr>\n    <tr>\n      <th>330293</th>\n      <td>TRAIN_330961.jpg</td>\n      <td>HELOISE</td>\n      <td>7</td>\n      <td>[7.0, 4.0, 11.0, 14.0, 8.0, 18.0, 4.0, 0.0, 0....</td>\n    </tr>\n  </tbody>\n</table>\n<p>330294 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(df_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:07:56.563906Z","iopub.execute_input":"2021-08-10T17:07:56.564277Z","iopub.status.idle":"2021-08-10T17:07:56.571053Z","shell.execute_reply.started":"2021-08-10T17:07:56.564239Z","shell.execute_reply":"2021-08-10T17:07:56.569927Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"330294"},"metadata":{}}]},{"cell_type":"code","source":"# Create a dataset \n\nclass HandwritingDataset(Dataset):\n    def __init__(self, df, folder_path):\n        self.df = df\n        self.folder_path = folder_path  # ex. '/content/train_v2/train/'\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # retrieve image\n        path = self.folder_path+self.df.loc[idx,'FILENAME']\n        \n        # read the img\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        \n        img = preprocess(img)\n        \n        # convert to [0,1] scale -> normalize\n        img = torch.tensor(img / 255.).float()\n        \n        # Encode the label \n        label = torch.tensor(self.df.loc[idx,'ENCODED LABEL'])\n        #label = torch.tensor(label_to_num(self.df.loc[idx,'IDENTITY'])) # Returns label as a sequence of numbers \n        label_length = self.df.loc[idx,'LABEL LENGTH']\n        \n        return img, label, label_length","metadata":{"id":"NVZ180TbIp3V","execution":{"iopub.status.busy":"2021-08-10T17:07:56.572929Z","iopub.execute_input":"2021-08-10T17:07:56.573393Z","iopub.status.idle":"2021-08-10T17:07:56.583542Z","shell.execute_reply.started":"2021-08-10T17:07:56.573351Z","shell.execute_reply":"2021-08-10T17:07:56.582195Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## CNN Architecture --> RNN Arhitecture\n","metadata":{"id":"-pS7tEE3XK8r"}},{"cell_type":"code","source":"class Mish(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        return (x*torch.tanh(F.softplus(x)))","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:07:56.585303Z","iopub.execute_input":"2021-08-10T17:07:56.585918Z","iopub.status.idle":"2021-08-10T17:07:56.594018Z","shell.execute_reply.started":"2021-08-10T17:07:56.585873Z","shell.execute_reply":"2021-08-10T17:07:56.593025Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class CNN_RNN(nn.Module):\n    \"\"\"CNN and RNN model from class\"\"\"\n    def __init__(self, mish=False):\n        super().__init__()\n        \n        # same padding!\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n        \n        # pooling\n        self.pool_1 = nn.MaxPool2d(kernel_size=2)\n        self.pool_2 = nn.MaxPool2d(kernel_size=(1,2))\n    \n        # activation\n        self.relu = nn.ReLU()\n        if mish:\n            self.relu = Mish()\n\n        # batchnorm\n        self.bn1 = nn.BatchNorm2d(32)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.bn3 = nn.BatchNorm2d(128)\n\n        # Linear Layer (Dense Layer)\n        self.linear1 = nn.Linear(in_features=1024, out_features=64)\n        self.linear2 = nn.Linear(in_features=1024, out_features=30)\n\n        # RNN Layer --> Single LSTM with num_layers=2\n        self.lstm1 = nn.LSTM(input_size=64, hidden_size=512, batch_first=True, bidirectional=True, num_layers=2)\n\n        #self.unroll = nn.Flatten()\n        \n        #self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        \n        # CNN\n        # Start with image that is 256 wide x 64 tall and 1 channel\n        # End with 64 wide x 8 tall and 128 channels\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.pool_1(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.pool_1(x)\n        \n        x = self.conv3(x)\n        x = self.bn3(x)\n        x = self.relu(x)\n        x = self.pool_2(x)\n        \n\n        # CNN to RNN\n        # Reshape to a sequence vector that is 64 wide and 1024 deep \n        batch_size = x.shape[0]\n\n        x = torch.reshape(x,(batch_size,64,-1)) # or 1024 instead of -1?? \n        \n        # Now we shrink the sequence vector to be 512 deep \n        x = self.linear1(x) \n        \n        x = self.lstm1(x)[0] #[0] to get outputs, not hidden\n\n        # OUTPUT\n        x = self.linear2(x) # torch.Size([2, 2, 30])\n\n        return x\n","metadata":{"id":"rH4LIYXxD8Kn","execution":{"iopub.status.busy":"2021-08-10T17:07:56.595695Z","iopub.execute_input":"2021-08-10T17:07:56.596179Z","iopub.status.idle":"2021-08-10T17:07:56.611297Z","shell.execute_reply.started":"2021-08-10T17:07:56.596136Z","shell.execute_reply":"2021-08-10T17:07:56.610395Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = CNN_RNN(mish=True)\nsummary(model, input_size = (2, 1, 256, 64), device='cpu')  # inputsize = (batch_size, channels, image length, image width)\n","metadata":{"id":"elpMbwanO5TY","outputId":"7b19b1ba-7b37-4beb-a171-90c76cbe3f13","execution":{"iopub.status.busy":"2021-08-10T17:07:56.613074Z","iopub.execute_input":"2021-08-10T17:07:56.613889Z","iopub.status.idle":"2021-08-10T17:07:57.015393Z","shell.execute_reply.started":"2021-08-10T17:07:56.613847Z","shell.execute_reply":"2021-08-10T17:07:57.014486Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nCNN_RNN                                  --                        --\n├─Conv2d: 1-1                            [2, 32, 256, 64]          320\n├─BatchNorm2d: 1-2                       [2, 32, 256, 64]          64\n├─Mish: 1-3                              [2, 32, 256, 64]          --\n├─MaxPool2d: 1-4                         [2, 32, 128, 32]          --\n├─Conv2d: 1-5                            [2, 64, 128, 32]          18,496\n├─BatchNorm2d: 1-6                       [2, 64, 128, 32]          128\n├─Mish: 1-7                              [2, 64, 128, 32]          --\n├─MaxPool2d: 1-8                         [2, 64, 64, 16]           --\n├─Conv2d: 1-9                            [2, 128, 64, 16]          73,856\n├─BatchNorm2d: 1-10                      [2, 128, 64, 16]          256\n├─Mish: 1-11                             [2, 128, 64, 16]          --\n├─MaxPool2d: 1-12                        [2, 128, 64, 8]           --\n├─Linear: 1-13                           [2, 64, 64]               65,600\n├─LSTM: 1-14                             [2, 64, 1024]             8,667,136\n├─Linear: 1-15                           [2, 64, 30]               30,750\n==========================================================================================\nTotal params: 8,856,606\nTrainable params: 8,856,606\nNon-trainable params: 0\nTotal mult-adds (G): 1.42\n==========================================================================================\nInput size (MB): 0.13\nForward/backward pass size (MB): 30.50\nParams size (MB): 35.43\nEstimated Total Size (MB): 66.06\n=========================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"def one_pass(model, dataloader, optimizer, backwards=True, print_loss=True):\n    \n    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 100)   \n    lossFun = nn.CTCLoss()\n    \n    if backwards == True:\n        model.train()\n    else:\n        model.eval()\n    \n    total_loss = 0\n    total_correct_char = 0\n    correct = 0\n    correct_chars = 0\n    total_chars = 0\n    for img, labels, label_length in dataloader:\n        \n        # Send to GPU\n        img = img.to(device)\n        labels = labels.to(device)\n        label_length = label_length.to(device)\n        \n        \n        model.train()\n        y_pred = model(img.unsqueeze(1))\n        lsm = nn.LogSoftmax()\n        y_pred = lsm(y_pred)\n\n        yinput = y_pred.permute(1,0,2)  # input sequence length, batch_size, number of classes \n\n        N = labels.shape[0] # batch size \n        input_lengths = torch.ones(N,dtype=torch.long)*64\n\n        loss = lossFun(yinput, labels, input_lengths, label_length)\n        total_loss += loss.item()\n        \n        if backwards == True:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            lr_scheduler.step()\n\n  \n        # ACCURACY \n        \n        pred_nums = torch.argmax(y_pred, dim=2)\n        \n        # Character accuracy\n        for pred, label, length in zip(pred_nums, labels, label_length):\n            length = length.item()\n            pred = torch.split(pred, length, dim=0)\n            pred = pred[0]\n            label = torch.split(label, length, dim=0)\n            label = label[0]\n            correct_chars += torch.sum(pred==label) \n            total_chars += length\n\n                    \n        # Check if words are same\n        for i in range(N):\n            pr = pred_nums[i]\n            tr = labels[i]\n            if torch.equal(pr, tr.long()):\n                correct +=1\n                \n    avg_loss = total_loss / len(dataloader)\n    avg_correct_chars = correct_chars/total_chars\n    \n    return avg_loss, avg_correct_chars, correct","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:07:57.016942Z","iopub.execute_input":"2021-08-10T17:07:57.017343Z","iopub.status.idle":"2021-08-10T17:07:57.031699Z","shell.execute_reply.started":"2021-08-10T17:07:57.017302Z","shell.execute_reply":"2021-08-10T17:07:57.030361Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train_epochs_gpu(batch_size, lr, num_epochs):\n    \n    dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n    dl_valid = DataLoader(ds_valid, batch_size=batch_size, shuffle=False)\n    \n    # model with mish activation function\n    model = CNN_RNN(mish=True)\n    optimizer = optim.Adam(model.parameters(), lr=lr )\n\n    model = model.to(device)\n\n    train_losses = []\n    valid_losses = []\n    train_correct_chars = []\n    valid_correct_chars = []\n    train_correct_words = []\n    valid_correct_words = []\n    for epoch in range(num_epochs):\n        print('Epoch: ', epoch)\n\n        train_avg_loss, train_avg_correct_chars, train_num_correct_words = one_pass(model, dl_train, optimizer)\n        train_losses.append(train_avg_loss)\n        train_correct_chars.append(train_avg_correct_chars.item())\n        train_correct_words.append(train_num_correct_words)\n        print(\"Train:\")\n        print(\"CTC Loss:\", round(train_avg_loss,4))\n        print(\"Percent correct characters per word:\", round(train_avg_correct_chars.item(),4))\n        print(\"Number of correct words:\", train_num_correct_words)\n\n\n        valid_avg_loss, valid_avg_correct_chars, valid_num_correct_words = one_pass(model, dl_valid, optimizer, backwards=False)\n        valid_losses.append(valid_avg_loss)\n        valid_correct_chars.append(valid_avg_correct_chars.item())\n        valid_correct_words.append(valid_num_correct_words)\n        print(\"Valid\")\n        print(\"CTC Loss\", round(valid_avg_loss,4))\n        print(\"Percent correct characters per word\", round(valid_avg_correct_chars.item(),4))\n        print(\"Number of correct words\", valid_num_correct_words)\n        print(\"\")\n        \n    return train_losses, valid_losses, valid_correct_chars, valid_correct_words","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:07:57.033567Z","iopub.execute_input":"2021-08-10T17:07:57.034102Z","iopub.status.idle":"2021-08-10T17:07:57.049669Z","shell.execute_reply.started":"2021-08-10T17:07:57.034040Z","shell.execute_reply":"2021-08-10T17:07:57.048747Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice = torch.device(0)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:07:57.051428Z","iopub.execute_input":"2021-08-10T17:07:57.051905Z","iopub.status.idle":"2021-08-10T17:07:57.104643Z","shell.execute_reply.started":"2021-08-10T17:07:57.051862Z","shell.execute_reply":"2021-08-10T17:07:57.103614Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Create mini datasets for testing\n\ndf_mini_train = df_train.iloc[:1000]\nds_train = HandwritingDataset(df_mini_train, '/kaggle/input/handwriting-recognition/train_v2/train/')\n\ndf_mini_valid = df_valid.iloc[:100]\nds_valid = HandwritingDataset(df_mini_valid, '/kaggle/input/handwriting-recognition/validation_v2/validation/')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:07:57.106253Z","iopub.execute_input":"2021-08-10T17:07:57.107012Z","iopub.status.idle":"2021-08-10T17:07:57.115794Z","shell.execute_reply.started":"2021-08-10T17:07:57.106955Z","shell.execute_reply":"2021-08-10T17:07:57.114836Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Create dataloaders \n\ndl_train = DataLoader(ds_train, batch_size = 32, shuffle=True)\ndl_valid = DataLoader(ds_valid, batch_size = 32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:07:57.120067Z","iopub.execute_input":"2021-08-10T17:07:57.120503Z","iopub.status.idle":"2021-08-10T17:07:57.128904Z","shell.execute_reply.started":"2021-08-10T17:07:57.120472Z","shell.execute_reply":"2021-08-10T17:07:57.127964Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Test functions on mini dataset \n\ntrain_losses, valid_losses, valid_correct_chars, valid_correct_words = train_epochs_gpu(batch_size=32, lr=0.001, num_epochs=5)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:07:57.130842Z","iopub.execute_input":"2021-08-10T17:07:57.131551Z","iopub.status.idle":"2021-08-10T17:09:05.474658Z","shell.execute_reply.started":"2021-08-10T17:07:57.131506Z","shell.execute_reply":"2021-08-10T17:09:05.473608Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch:  0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","output_type":"stream"},{"name":"stdout","text":"Train:\nCTC Loss: 26.2691\nPercent correct characters per word: 0.0809\nNumber of correct words: 0\nValid\nCTC Loss 20.5455\nPercent correct characters per word 0.0949\nNumber of correct words 0\n\nEpoch:  1\nTrain:\nCTC Loss: 25.0529\nPercent correct characters per word: 0.0683\nNumber of correct words: 0\nValid\nCTC Loss 19.937\nPercent correct characters per word 0.0735\nNumber of correct words 0\n\nEpoch:  2\nTrain:\nCTC Loss: 23.9254\nPercent correct characters per word: 0.0772\nNumber of correct words: 0\nValid\nCTC Loss 20.1873\nPercent correct characters per word 0.0582\nNumber of correct words 0\n\nEpoch:  3\nTrain:\nCTC Loss: 24.5009\nPercent correct characters per word: 0.0659\nNumber of correct words: 0\nValid\nCTC Loss 19.8191\nPercent correct characters per word 0.0628\nNumber of correct words 0\n\nEpoch:  4\nTrain:\nCTC Loss: 23.7907\nPercent correct characters per word: 0.0623\nNumber of correct words: 0\nValid\nCTC Loss 20.1862\nPercent correct characters per word 0.0597\nNumber of correct words 0\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_losses)\nprint(valid_losses)\nprint(valid_correct_chars)\nprint(valid_correct_words) ","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:09:05.476311Z","iopub.execute_input":"2021-08-10T17:09:05.476901Z","iopub.status.idle":"2021-08-10T17:09:05.483368Z","shell.execute_reply.started":"2021-08-10T17:09:05.476856Z","shell.execute_reply":"2021-08-10T17:09:05.482420Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"[26.26910811662674, 25.052927374839783, 23.925353676080704, 24.500934571027756, 23.790739744901657]\n[20.545480370521545, 19.937028467655182, 20.187299728393555, 19.81905573606491, 20.186236143112183]\n[0.09494640678167343, 0.07350689172744751, 0.05819295719265938, 0.06278713792562485, 0.0597243495285511]\n[0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train for real on 1 epochs --> started at 8:47am on Tuesday\n\nds_train = HandwritingDataset(df_train, '/kaggle/input/handwriting-recognition/train_v2/train/')\nds_valid = HandwritingDataset(df_valid, '/kaggle/input/handwriting-recognition/validation_v2/validation/')\n\ndl_train = DataLoader(ds_train, batch_size = 32, shuffle=True)\ndl_valid = DataLoader(ds_valid, batch_size = 32, shuffle=False)\n\ntrain_losses, valid_losses, valid_correct_chars, valid_correct_words = train_epochs_gpu(batch_size=32, lr=0.001, num_epochs=20)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:09:05.484834Z","iopub.execute_input":"2021-08-10T17:09:05.485457Z","iopub.status.idle":"2021-08-10T18:06:53.831146Z","shell.execute_reply.started":"2021-08-10T17:09:05.485400Z","shell.execute_reply":"2021-08-10T18:06:53.829222Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch:  0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","output_type":"stream"},{"name":"stdout","text":"Train:\nCTC Loss: 24.0105\nPercent correct characters per word: 0.0697\nNumber of correct words: 29\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-f78b91dfcaec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdl_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_correct_chars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_correct_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epochs_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-efab8c04a682>\u001b[0m in \u001b[0;36mtrain_epochs_gpu\u001b[0;34m(batch_size, lr, num_epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mvalid_avg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_avg_correct_chars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_num_correct_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackwards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mvalid_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_avg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mvalid_correct_chars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_avg_correct_chars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-d0eb8fc31244>\u001b[0m in \u001b[0;36mone_pass\u001b[0;34m(model, dataloader, optimizer, backwards, print_loss)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcorrect_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtotal_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_length\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Send to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-f6c06a91fd0c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# read the img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Train for real on 20 epochs --> started at 8:47am on Tuesday\n\nds_train = HandwritingDataset(df_train, '/kaggle/input/handwriting-recognition/train_v2/train/')\nds_valid = HandwritingDataset(df_valid, '/kaggle/input/handwriting-recognition/validation_v2/validation/')\n\ndl_train = DataLoader(ds_train, batch_size = 32, shuffle=True)\ndl_valid = DataLoader(ds_valid, batch_size = 32, shuffle=False)\n\ntrain_losses, valid_losses, valid_correct_chars, valid_correct_words = train_epochs_gpu(batch_size=32, lr=0.001, num_epochs=20)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T18:07:21.009882Z","iopub.execute_input":"2021-08-10T18:07:21.010214Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch:  0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","output_type":"stream"},{"name":"stdout","text":"Train:\nCTC Loss: 24.1788\nPercent correct characters per word: 0.0704\nNumber of correct words: 14\nValid\nCTC Loss 22.5502\nPercent correct characters per word 0.0836\nNumber of correct words 1\n\nEpoch:  1\nTrain:\nCTC Loss: 21.6404\nPercent correct characters per word: 0.1021\nNumber of correct words: 7\nValid\nCTC Loss 20.377\nPercent correct characters per word 0.1222\nNumber of correct words 0\n\nEpoch:  2\nTrain:\nCTC Loss: 19.6929\nPercent correct characters per word: 0.1265\nNumber of correct words: 8\nValid\nCTC Loss 18.1404\nPercent correct characters per word 0.1396\nNumber of correct words 0\n\nEpoch:  3\nTrain:\nCTC Loss: 17.1576\nPercent correct characters per word: 0.1613\nNumber of correct words: 3\nValid\nCTC Loss 16.0976\nPercent correct characters per word 0.1783\nNumber of correct words 1\n\nEpoch:  4\nTrain:\nCTC Loss: 15.2663\nPercent correct characters per word: 0.1828\nNumber of correct words: 7\nValid\nCTC Loss 14.5922\nPercent correct characters per word 0.1861\nNumber of correct words 2\n\nEpoch:  5\nTrain:\nCTC Loss: 14.442\nPercent correct characters per word: 0.1867\nNumber of correct words: 7\nValid\nCTC Loss 14.3449\nPercent correct characters per word 0.188\nNumber of correct words 1\n\nEpoch:  6\nTrain:\nCTC Loss: 14.2996\nPercent correct characters per word: 0.1865\nNumber of correct words: 4\nValid\nCTC Loss 14.2341\nPercent correct characters per word 0.1863\nNumber of correct words 1\n\nEpoch:  7\nTrain:\nCTC Loss: 14.2346\nPercent correct characters per word: 0.1862\nNumber of correct words: 5\nValid\nCTC Loss 14.1912\nPercent correct characters per word 0.1866\nNumber of correct words 1\n\nEpoch:  8\nTrain:\nCTC Loss: 14.1888\nPercent correct characters per word: 0.1854\nNumber of correct words: 6\nValid\nCTC Loss 14.2043\nPercent correct characters per word 0.1858\nNumber of correct words 0\n\nEpoch:  9\nTrain:\nCTC Loss: 14.1797\nPercent correct characters per word: 0.185\nNumber of correct words: 4\nValid\nCTC Loss 14.1815\nPercent correct characters per word 0.1849\nNumber of correct words 0\n\nEpoch:  10\nTrain:\nCTC Loss: 14.1548\nPercent correct characters per word: 0.1848\nNumber of correct words: 4\nValid\nCTC Loss 14.1342\nPercent correct characters per word 0.1851\nNumber of correct words 0\n\nEpoch:  11\nTrain:\nCTC Loss: 14.0764\nPercent correct characters per word: 0.1854\nNumber of correct words: 3\nValid\nCTC Loss 14.0637\nPercent correct characters per word 0.1855\nNumber of correct words 0\n\nEpoch:  12\nTrain:\nCTC Loss: 13.8924\nPercent correct characters per word: 0.1883\nNumber of correct words: 2\nValid\nCTC Loss 13.7483\nPercent correct characters per word 0.1915\nNumber of correct words 1\n\nEpoch:  13\nTrain:\nCTC Loss: 13.6438\nPercent correct characters per word: 0.1936\nNumber of correct words: 11\nValid\nCTC Loss 13.5498\nPercent correct characters per word 0.1953\nNumber of correct words 1\n\nEpoch:  14\nTrain:\nCTC Loss: 13.4237\nPercent correct characters per word: 0.1979\nNumber of correct words: 5\nValid\nCTC Loss 13.0708\nPercent correct characters per word 0.2007\nNumber of correct words 1\n\nEpoch:  15\nTrain:\nCTC Loss: nan\nPercent correct characters per word: 0.1662\nNumber of correct words: 22\nValid\nCTC Loss nan\nPercent correct characters per word 0.1246\nNumber of correct words 5\n\nEpoch:  16\nTrain:\nCTC Loss: nan\nPercent correct characters per word: 0.1246\nNumber of correct words: 31\nValid\nCTC Loss nan\nPercent correct characters per word 0.1246\nNumber of correct words 5\n\nEpoch:  17\n","output_type":"stream"}]}]}